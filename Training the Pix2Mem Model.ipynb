{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to train a neural network using images and memory. Note that the dirs variable shoould be the path to the data folder containing a folder called screenshots and another folder called states. There should be respectively images and memory files in each folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import average_precision_score\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = '' #Path to the data folder\n",
    "\n",
    "#The corresponding image and memory file should have the same numeric name\n",
    "#indicating the frame count. Run \"Working with Human Data\" notebook for example\n",
    "img_paths = sorted(glob(dirs + '/screenshots/*'),\n",
    "                   key=lambda name: int(name[len(dirs)+13:-4]))\n",
    "mem_paths = sorted(glob(dirs + '/states/*'),\n",
    "                   key=lambda name: int(name[len(dirs)+8:-4]))\n",
    "\n",
    "img_num = len(img_paths)\n",
    "if img_num != len(mem_paths):\n",
    "    raise Exception('The amount of screenshots and states are different')\n",
    "    \n",
    "img_height, img_width, img_channel = imread(img_paths[0]).shape\n",
    "ram_size = 4096\n",
    "\n",
    "print('Number of images:', img_num)\n",
    "print('Image shape: (%i, %i, %i)' % (img_height, img_width, img_channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct neural network\n",
    "\n",
    "def make_layers(input_layer, filters, window_size, strides, activation, dropout_rate):\n",
    "    x = layers.Conv2D(filters, window_size, strides=strides, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "input_img = layers.Input(shape=(img_height, img_width, img_channel))\n",
    "\n",
    "x = make_layers(input_img, 16, 3, 2, 'elu', 0.5)\n",
    "x = make_layers(x, 32, 3, 2, 'elu', 0.5)\n",
    "x = make_layers(x, 64, 3, 2, 'elu', 0.5)\n",
    "x = make_layers(x, 64, 3, 2, 'elu', 0.5)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu', name='Embedded')(x)\n",
    "embedded = x\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(ram_size * 4)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Reshape((ram_size, 4))(x)\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_img, x)\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#An array of values to an array of one hot vectors\n",
    "def byte_values_to_categorical(y):\n",
    "    y = y.ravel()\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, 256), dtype=np.uint8)\n",
    "    categorical[arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "#An array of one hot vectors to an array of values\n",
    "def categorical_to_byte_values(y):\n",
    "    return argmax(y, axis=2).astype(np.uint8)\n",
    "\n",
    "#Training data generator\n",
    "def gen(arr, batch_size):\n",
    "    i = 0\n",
    "    total_num = len(arr)\n",
    "    while True:\n",
    "        temp_arr = arr[i * batch_size:(i + 1) * batch_size]\n",
    "        length = len(temp_arr)\n",
    "        temp_screenshots = np.zeros((length, img_height, img_width, img_channel))\n",
    "        temp_states = np.zeros((length, ram_size))\n",
    "        for j in range(length):\n",
    "            temp_num = temp_arr[j]\n",
    "            temp_screenshots[j] = imread(img_paths[temp_num])\n",
    "            with open(mem_paths[temp_num], 'rb') as f:\n",
    "                temp_states[j] = np.frombuffer(f.read()[:ram_size], dtype=np.uint8)\n",
    "        temp_real_states = byte_values_to_categorical(temp_states.astype(np.uint8)).reshape(-1, ram_size, 256)\n",
    "        i += 1\n",
    "        if i * batch_size >= total_num:\n",
    "            i = 0\n",
    "        yield temp_screenshots, temp_real_states\n",
    "        \n",
    "batch_size = 16\n",
    "this_arr = arange(1, img_num)\n",
    "np.random.shuffle(this_arr)\n",
    "split = img_num // 10\n",
    "validation_arr = this_arr[8 * split:9 * split]\n",
    "test_arr = this_arr[9 * split:]\n",
    "train_arr = this_arr[:8 * split]\n",
    "history = model.fit_generator(gen(train_arr, batch_size),\n",
    "                              steps_per_epoch=int(len(this_arr) / batch_size) + 1,\n",
    "                              epochs=20,\n",
    "                              validation_data=gen(validation_arr, batch_size),\n",
    "                              validation_steps=int(len(validation_arr) / batch_size) + 1,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mAP(vectors, t):\n",
    "    special_frames = list(range(0, len(vectors), 60))\n",
    "    results = []\n",
    "    normalized_vectors = vectors / norm(vectors, axis=1).reshape((-1, 1))\n",
    "    \n",
    "    for special_frame in special_frames:\n",
    "        y_true = array([abs(i - special_frame) <= t for i in range(len(vectors))])\n",
    "        target = normalized_vectors[special_frame]\n",
    "        scores = dot(normalized_vectors, target)\n",
    "        y_true[special_frame] = False\n",
    "        scores[special_frame] = min(scores)\n",
    "        results.append(average_precision_score(y_true, scores))\n",
    "    return mean(results)\n",
    "\n",
    "#Get em\n",
    "embedded_model = Model(model.input, embedded)\n",
    "this_arr = arange(img_num)\n",
    "embedding = embedded_model.predict_generator(gen(this_arr, batch_size),\n",
    "                                             steps=int(len(this_arr) / batch_size) + 1,\n",
    "                                             verbose=1)\n",
    "\n",
    "#Geeting mean average precision\n",
    "print('2 Seconds:', mAP(embedding, 1))\n",
    "print('10 Seconds:', mAP(embedding, 5))\n",
    "print('60 Seconds:', mAP(embedding, 30))\n",
    "\n",
    "#Save the full model and embedding model\n",
    "model.save('full_model.h5')\n",
    "embedded_model.save('embedding_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
